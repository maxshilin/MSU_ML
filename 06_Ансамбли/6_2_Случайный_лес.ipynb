{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upU8iWtojlkk"
      },
      "source": [
        "# 6.2. Случайный лес\n",
        "\n",
        "Ваша задача - написать класс `random_forest` для решения задачи классификации на основе датасета Ирисов Фишера (`sklearn.datasets.load_iris`), принимающий на вход конструктора аргументы `n_estimators`, `max_depth`, `subspaces_dim` и `random_state`. описание этих аргументов приведено ниже. У этого класса должны быть определены методы `.fit()` и `.predict()`, а также поле `._estimators`, в котором должен храниться список алгоритмов, используемых в ансамбле. \n",
        "\n",
        "Для создания обучающей подвыборки для каждого из базовых классификаторов, Вы можете воспользоваться классом `sample`, который Вы реализовали в прошлом задании. В случае его использования, не забудьте включить его описание в файл с Вашим решением текущего задания. Мы также предлагаем вам организовать выбор подпространств для каждого дерева посредством заполнения списка `subspace_idx`, в котором будут логироваться выбранные для каждого базового классификатора подпространства.\n",
        "\n",
        "Замечание: в рамках выполнения данного задания запрещено использовать класс `sklearn.ensemble.RandomForestClassifier`. Такой код не пройдёт проверку.\n",
        "\n",
        "Подберите также гиперпараметры, на которых ваш алгоритм получает наилучшее качество (с точки зрения метрики accuracy, доли правильных ответов) на тестовой выборке с параметром `test_size`=0.3, задайте их в виде глобальных переменных N_ESTIMATORS, MAX_DEPTH, SUBSPACE_DIM.\n",
        "\n",
        "Шаблон класса:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GLfTj8FHjvY2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "class sample(object):\n",
        "    def __init__(self, X, n_subspace):\n",
        "        self.idx_subspace = self.random_subspace(X, n_subspace)\n",
        "\n",
        "    def __call__(self, X, y):\n",
        "        idx_obj = self.bootstrap_sample(X)\n",
        "        X_sampled, y_sampled = self.get_subsample(\n",
        "            X, y, self.idx_subspace, idx_obj\n",
        "        )\n",
        "        return X_sampled, y_sampled\n",
        "\n",
        "    @staticmethod\n",
        "    def bootstrap_sample(X):\n",
        "        return np.unique(np.random.choice(X.shape[0], X.shape[0]))\n",
        "\n",
        "    @staticmethod\n",
        "    def random_subspace(X, n_subspace):\n",
        "        return np.sort(np.random.choice(X.shape[1], n_subspace, replace=False))\n",
        "\n",
        "    @staticmethod\n",
        "    def get_subsample(X, y, idx_subspace, idx_obj):\n",
        "        X_new = X[idx_obj]\n",
        "        X_sample = np.empty((idx_obj.shape[0], idx_subspace.shape[0]), dtype=np.float64)\n",
        "\n",
        "        for i, x in enumerate(X_new):\n",
        "            X_sample[i] = x[idx_subspace]\n",
        "\n",
        "        return X_sample, y[idx_obj]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class random_forest(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_estimators: int,\n",
        "        max_depth: int,\n",
        "        subspaces_dim: int,\n",
        "        random_state: int,\n",
        "    ):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.subspaces_dim = subspaces_dim\n",
        "        self.random_state = random_state\n",
        "        self.Classifier = []\n",
        "        self.subspace_idx = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.n_estimators):\n",
        "            s = sample(X, self.subspaces_dim)\n",
        "            X_sample, y_sample = s(X, y)\n",
        "            self.Classifier.append(\n",
        "                DecisionTreeClassifier(max_depth=self.max_depth).fit(\n",
        "                    X_sample, y_sample\n",
        "                )\n",
        "            )\n",
        "            self.subspace_idx.append(s.idx_subspace)\n",
        "\n",
        "    def predict(self, X):\n",
        "        tmp = np.empty((self.n_estimators, X.shape[0]), dtype=np.float64)\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            idx_subspace = self.subspace_idx[i]\n",
        "            X_sample = np.empty(\n",
        "                (X.shape[0], idx_subspace.shape[0]), dtype=np.float64\n",
        "            )\n",
        "\n",
        "            for j, x in enumerate(X):\n",
        "                X_sample[j] = x[idx_subspace]\n",
        "\n",
        "            tmp[i, :] = self.Classifier[i].predict(X_sample)\n",
        "        out = tmp.T\n",
        "        predicted = np.zeros(X.shape[0], dtype=int)\n",
        "\n",
        "        for i, x in enumerate(out):\n",
        "            counter = Counter(x)\n",
        "            predicted[i] = counter.most_common(1)[0][0]\n",
        "\n",
        "        return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, 2, 0)\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, shuffle=True, random_state=42\n",
        ")\n",
        "accuracy = np.empty((20, 20, 4), dtype=np.float64)\n",
        "\n",
        "for n_estimators in range(1, 21):\n",
        "    for max_depth in range(1, 21):\n",
        "        for subspace_dim in range(1, 5):\n",
        "            clf = random_forest(n_estimators, max_depth, subspace_dim, 42)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(x_test)\n",
        "            accuracy[\n",
        "                n_estimators - 1, max_depth - 1, subspace_dim - 1\n",
        "            ] = accuracy_score(y_test, y_pred)\n",
        " \n",
        "ind = np.unravel_index(np.argmax(accuracy, axis=None), accuracy.shape)\n",
        "print(ind)\n",
        "print(accuracy[ind[0], ind[1], ind[2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "c2032020440b0bd724902a671edb93f8cebb68488612e100320a0417abc157de"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
